{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data.tsv',sep='\\t',quoting=3,names = ['keys','sub'])\n",
    "\n",
    "#NOT USED\n",
    "dataset['sub'] = dataset['sub'].astype('category')\n",
    "dataset['sub'] = dataset['sub'].cat.codes\n",
    "#for one hot encoding\n",
    "dataset = pd.get_dummies(dataset, columns=[\"sub\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "for i in range(1, 621286):\n",
    "    line = dataset['keys'][i]\n",
    "    keywords = line.split()\n",
    "    keywords = [key.lower() for key in keywords]\n",
    "    keywords = [ps.stem(word) for word in keywords if not word in set(stopwords.words('english'))]\n",
    "    keywords = ' '.join(keywords)\n",
    "    corpus.append(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus)\n",
    "#X = X.toarray()\n",
    "\n",
    "y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing to MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing to Decistion Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing to Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting to Classifier\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "import pickle\n",
    "pickle.dump(classifier, open('classifier.pkl', 'wb'))\n",
    "pickle.dump(cv, open('cv.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(random_state=0)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "#loading model from file\n",
    "classifier = pickle.load(open('classifier.pkl','rb'))\n",
    "cv = pickle.load(open('cv.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Prediction\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "query = 'android'\n",
    "query = query.split()\n",
    "query = [ps.stem(word) for word in query if not word in set(stopwords.words('english'))]\n",
    "X_test = cv.transform([' '.join(query)])\n",
    "ypred = classifier.predict(X_test.toarray())\n",
    "ypred2 = classifier.predict_proba(X_test.toarray()).T\n",
    "output = str(ypred[0])\n",
    "classes = classifier.classes_.tolist()\n",
    "subjects = [] \n",
    "while(True):\n",
    "    val = ypred2.argmax(axis=0)\n",
    "    print(val)\n",
    "    if(ypred2[val][0] == 0):\n",
    "        break\n",
    "    subjects.append(val)\n",
    "    ypred2[val]=[0]\n",
    "\n",
    "#Subjects contains all predictions for subjects related to query\n",
    "subjects = [classes[i[0]] for i in subjects]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
